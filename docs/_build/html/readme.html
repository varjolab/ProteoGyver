

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Proteogyver &mdash; ProteoGyver 1.05 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8214e1ae"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            ProteoGyver
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Proteogyver</a><ul>
<li><a class="reference internal" href="#table-of-contents">Table of contents:</a></li>
<li><a class="reference internal" href="#security">Security</a></li>
<li><a class="reference internal" href="#qc-and-quick-analysis-toolset">QC and quick analysis toolset</a><ul>
<li><a class="reference internal" href="#core-analysis-workflows">Core Analysis Workflows</a></li>
<li><a class="reference internal" href="#usage">Usage</a></li>
<li><a class="reference internal" href="#input-data-format">Input Data Format</a></li>
</ul>
</li>
<li><a class="reference internal" href="#additional-tools">Additional Tools</a><ul>
<li><a class="reference internal" href="#microscopy-colocalizer">Microscopy Colocalizer</a><ul>
<li><a class="reference internal" href="#features">Features</a></li>
<li><a class="reference internal" href="#id1">Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ms-inspector">MS Inspector</a><ul>
<li><a class="reference internal" href="#id2">Features</a></li>
<li><a class="reference internal" href="#id3">Usage</a></li>
<li><a class="reference internal" href="#notes">Notes</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#installation">Installation</a><ul>
<li><a class="reference internal" href="#ms-run-data-pre-analysis">MS run data pre-analysis</a></li>
<li><a class="reference internal" href="#demo-image-for-testing-use">Demo image for testing use</a></li>
<li><a class="reference internal" href="#docker-installation-recommended-use-case">Docker Installation (recommended use case)</a><ul>
<li><a class="reference internal" href="#build-the-docker-images-and-run-the-pg-updater">Build the Docker images and run the PG updater</a><ul>
<li><a class="reference internal" href="#prerequisites">Prerequisites:</a></li>
<li><a class="reference internal" href="#used-api-data">Used API data</a></li>
<li><a class="reference internal" href="#build-the-main-docker-image">Build the main docker image.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#changing-parameters">Changing parameters</a></li>
<li><a class="reference internal" href="#run-the-container">Run the container</a><ul>
<li><a class="reference internal" href="#volume-paths">Volume paths</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#run-pg-locally-not-encouraged-but-possible">Run PG locally (not encouraged, but possible)</a><ul>
<li><a class="reference internal" href="#requirements-and-setup">Requirements and setup:</a></li>
<li><a class="reference internal" href="#run-pg">Run PG:</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#updating-the-database">Updating the database</a><ul>
<li><a class="reference internal" href="#update-running-order">Update running order:</a></li>
<li><a class="reference internal" href="#adding-ms-run-data">Adding MS run data</a></li>
<li><a class="reference internal" href="#adding-new-crapome-or-control-sets">Adding new crapome or control sets:</a></li>
<li><a class="reference internal" href="#adding-other-new-tables">Adding other new tables:</a></li>
<li><a class="reference internal" href="#deleting-data">Deleting data</a></li>
<li><a class="reference internal" href="#update-logging">Update logging</a></li>
</ul>
</li>
<li><a class="reference internal" href="#rare-use-cases">Rare use cases</a><ul>
<li><a class="reference internal" href="#embedding-other-websites-as-tabs-within-proteogyver">Embedding other websites as tabs within Proteogyver</a></li>
<li><a class="reference internal" href="#adding-custom-tools-as-tabs-to-proteogyver">Adding custom tools as tabs to Proteogyver</a></li>
<li><a class="reference internal" href="#accessing-the-database-from-other-tools">Accessing the database from other tools</a></li>
</ul>
</li>
<li><a class="reference internal" href="#citation">Citation</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ProteoGyver</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Proteogyver</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/readme.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="proteogyver">
<h1>Proteogyver<a class="headerlink" href="#proteogyver" title="Link to this heading"></a></h1>
<p>Proteogyver (PG) is a low-threshold, web-based platform for proteomics and interactomics data analysis. It provides tools for quality control, data visualization, and statistical analysis of mass spectrometry-based proteomics data. These should be used as rapid ways to get preliminary data (or in simple cases, publishable results) out of manageable chunks of MS rundata. PG is not intended to be a full-featured analysis platform, but rather a quick way to identify issues, characterize results, and move on to more detailed analysis. The additional tools of PG can be used for inspecting how MS is performing across a sample set (MS Inspector), and for generating colocalization heatmaps from microscopy data (Microscopy Colocalizer).</p>
<section id="table-of-contents">
<h2>Table of contents:<a class="headerlink" href="#table-of-contents" title="Link to this heading"></a></h2>
</section>
<section id="security">
<h2>Security<a class="headerlink" href="#security" title="Link to this heading"></a></h2>
<p>The app is insecure as it is. It is intended to be run on a network that is not exposed to the public internet, and contain data only accessible to trusted users.</p>
</section>
<section id="qc-and-quick-analysis-toolset">
<h2>QC and quick analysis toolset<a class="headerlink" href="#qc-and-quick-analysis-toolset" title="Link to this heading"></a></h2>
<section id="core-analysis-workflows">
<h3>Core Analysis Workflows<a class="headerlink" href="#core-analysis-workflows" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Proteomics Analysis</strong></p>
<ul>
<li><p>Missing value handling and imputation</p></li>
<li><p>Data normalization</p></li>
<li><p>Statistical analysis and visualization</p></li>
<li><p>Differential abundance analysis with volcano plots</p></li>
<li><p>Enrichment analysis</p></li>
</ul>
</li>
<li><p><strong>Interactomics Analysis</strong></p>
<ul>
<li><p>SAINT analysis integration</p></li>
<li><p>CRAPome filtering</p></li>
<li><p>Protein-protein interaction network visualization</p></li>
<li><p>MS-microscopy analysis</p></li>
<li><p>Known interaction mapping</p></li>
</ul>
</li>
</ul>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h3>
<p>Example files are downloadable from the sidebar of the main interface. These include example data files and sample tables for interactomics, and proteomics workflows.</p>
<ol class="arabic simple">
<li><p>Access the web interface (host:port, e.g. localhost:8050, if running locally)</p></li>
<li><p>Upload your data and sample tables</p></li>
<li><p>Choose your workflow (Proteomics or Interactomics)</p></li>
<li><p>Choose analysis parameters</p></li>
<li><p>Export results in various formats (HTML, PNG, PDF, TSV)</p></li>
</ol>
</section>
<section id="input-data-format">
<h3>Input Data Format<a class="headerlink" href="#input-data-format" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Sample table must include:</p>
<ul>
<li><p>“Sample name” column</p></li>
<li><p>“Sample group” column</p></li>
<li><p>“Bait uniprot” column (for interactomics)</p></li>
</ul>
</li>
<li><p>Supported data formats:</p>
<ul>
<li><p>Interactomics:</p>
<ul>
<li><p>FragPipe (combined_prot.tsv, reprint.spc)</p></li>
<li><p>Generic matrix format</p></li>
</ul>
</li>
<li><p>Proteomics:</p>
<ul>
<li><p>FragPipe (combined_prot.tsv)</p></li>
<li><p>DIA-NN (pg_matrix.tsv, report.tsv (discouraged due to size))</p></li>
<li><p>Generic matrix format</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="additional-tools">
<h2>Additional Tools<a class="headerlink" href="#additional-tools" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><strong>MS Inspector</strong>: Interactive visualization and analysis of MS performance through TIC graphs</p></li>
<li><p><strong>Microscopy Image Colocalizer</strong>: Analysis tool for .lif image files</p></li>
</ul>
<section id="microscopy-colocalizer">
<h3>Microscopy Colocalizer<a class="headerlink" href="#microscopy-colocalizer" title="Link to this heading"></a></h3>
<p>The Microscopy Colocalizer is a tool for analyzing spatial relationships between different fluorescent channels in microscopy images.</p>
<section id="features">
<h4>Features<a class="headerlink" href="#features" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Multi-channel image visualization</p></li>
<li><p>Colocalization analysis and colocalization map generation</p></li>
<li><p>Support for .lif (Leica), other formats may be supported in the future</p></li>
</ul>
</section>
<section id="id1">
<h4>Usage<a class="headerlink" href="#id1" title="Link to this heading"></a></h4>
<ol class="arabic simple">
<li><p>Upload your microscopy file (only .lif is supported for now)</p></li>
<li><p>Select channels for analysis</p></li>
<li><p>Select the Z-stack for analysis</p></li>
<li><p>Generate colocalization maps</p></li>
<li><p>Export results as merged channel visualizations from the upper right corner of the displayed images.</p></li>
</ol>
</section>
</section>
<section id="ms-inspector">
<h3>MS Inspector<a class="headerlink" href="#ms-inspector" title="Link to this heading"></a></h3>
<p>The MS Inspector is a tool for visualizing and analyzing Mass Spectrometry (MS) performance through chromatogram graphs and related metrics.</p>
<section id="id2">
<h4>Features<a class="headerlink" href="#id2" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Interactive TIC visualization with animation controls</p></li>
<li><p>Multiple trace types support (TIC, BPC)</p></li>
<li><p>Supplementary metrics tracking:</p>
<ul>
<li><p>Area Under the Curve (AUC)</p></li>
<li><p>Mean intensity</p></li>
<li><p>Maximum intensity</p></li>
</ul>
</li>
<li><p>Sample filtering by:</p>
<ul>
<li><p>Date range</p></li>
<li><p>Sample type</p></li>
<li><p>Run IDs</p></li>
</ul>
</li>
<li><p>Data export in multiple formats:</p>
<ul>
<li><p>HTML interactive plots</p></li>
<li><p>PNG images</p></li>
<li><p>PDF documents</p></li>
<li><p>TSV data files</p></li>
</ul>
</li>
</ul>
</section>
<section id="id3">
<h4>Usage<a class="headerlink" href="#id3" title="Link to this heading"></a></h4>
<ol class="arabic simple">
<li><p>Select MS instrument from dropdown</p></li>
<li><p>Choose analysis period</p></li>
<li><p>Filter by sample type(s) or input specific run IDs</p></li>
<li><p>Click “Load runs by selected parameters”</p></li>
<li><p>Use animation controls to explore TIC graphs as a time series:</p>
<ul class="simple">
<li><p>Start/Stop: Toggle automatic progression</p></li>
<li><p>Previous/Next: Manual navigation</p></li>
<li><p>Reset: Return to first run</p></li>
</ul>
</li>
<li><p>Switch between TIC and BPC metrics using dropdown</p></li>
<li><p>Export visualizations and data using “Download Data”</p></li>
</ol>
</section>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Maximum of 100 runs can be loaded at once</p></li>
<li><p>Multiple traces are displayed with decreasing opacity for temporal comparison</p></li>
<li><p>Supplementary metrics are synchronized with TIC visualization</p></li>
<li><p>For switching to a different run set, reload the page to ensure clean state</p></li>
<li><p>Prerequisite for the use of the tool, as well as chromatogram visualization in the QC workflow, is the pre-analysis of MS rawfiles and their inclusion into the PG database with the bundled database updater tool. See the “Updating the database” section for more information.</p></li>
</ul>
</section>
</section>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h2>
<section id="ms-run-data-pre-analysis">
<h3>MS run data pre-analysis<a class="headerlink" href="#ms-run-data-pre-analysis" title="Link to this heading"></a></h3>
<p>This is optional, but highly recommended. In order for the MS-inspector to have data to work with, or for QC to display chromatograms, information about MS runs needs to be included in the database.</p>
<p>MS run data needs to be pre-analyzed. As it may not be desirable to present run files directly to the server PG is running on, PG assumes that run file pre-analysis .json files are present in the directory specified in parameters.toml at “Maintenance”.”MS run parsing”.”Input files”. Te parser script is provided in utils folder (MSParser subdir), with its own conda environment .env file. MSParser.py can handle timsTOF and thermo data currently. Tested MS systems so far include the TimsTOF Pro, Pro2, QExactive, Orbitrap Elite, Astral, and Astral Zoom.</p>
<p>The parse_tims_data.py script requires four parameters:</p>
<ul class="simple">
<li><p>root directory, where the .d folders are located</p></li>
<li><p>output directory for json files</p></li>
<li><p>error file to write error information</p></li>
<li><p>parameters file (parameters.toml from PG repository).</p></li>
</ul>
</section>
<section id="demo-image-for-testing-use">
<h3>Demo image for testing use<a class="headerlink" href="#demo-image-for-testing-use" title="Link to this heading"></a></h3>
<p>Demo image is available in Zenodo (). However, few caveats apply:</p>
<ul class="simple">
<li><p>Database included in the demo image only contains the bare minimum required to use the test files, and all data within the database has been scrambled.</p></li>
<li><p>Similarly, SAINTExpress is not available on the demo image. This CAN be added by adding the executables to the container and making sure they are found in the path. However, we cannot distribute them by default.</p></li>
</ul>
</section>
<section id="docker-installation-recommended-use-case">
<h3>Docker Installation (recommended use case)<a class="headerlink" href="#docker-installation-recommended-use-case" title="Link to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">varjolab</span><span class="o">/</span><span class="n">Proteogyver</span><span class="o">/</span>
<span class="n">cd</span> <span class="n">Proteogyver</span>
</pre></div>
</div>
<section id="build-the-docker-images-and-run-the-pg-updater">
<h4>Build the Docker images and run the PG updater<a class="headerlink" href="#build-the-docker-images-and-run-the-pg-updater" title="Link to this heading"></a></h4>
<p>These commands may need sudo depending on the system.
PG updater is used to generate a database. A small test database is provided, and that works well with the example files that can be downloaded from the PG interface. The test database contains scrambled data, and is thus not recommended as a base for a production database. Proper database should be built before real use.</p>
<section id="prerequisites">
<h5>Prerequisites:<a class="headerlink" href="#prerequisites" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Download SAINTexpress from https://saint-apms.sourceforge.net/Main.html and place the <strong>linux</strong> executables into app/external/SAINTexpress:</p>
<ul>
<li><p>Folder structure should contain:
app/external/SAINTexpress/SAINTexpress-int
app/external/SAINTexpress/SAINTexpress-spc</p></li>
<li><p>These will be registered as executables and put into the path of the PG container during the container creation (see dockerfile)</p></li>
</ul>
</li>
<li><p>IF you want to use the CRAPome repository data, download it from https://reprint-apms.org/?q=data</p>
<ul>
<li><p>Afterwards, you need to format the data into a format usable by pg_updater, see <a class="reference internal" href="#updating-the-database"><span class="xref myst">Updating the database</span></a> for details</p></li>
</ul>
</li>
</ul>
</section>
<section id="used-api-data">
<h5>Used API data<a class="headerlink" href="#used-api-data" title="Link to this heading"></a></h5>
<p>During database building, PG downloads data from several sources:</p>
<ul class="simple">
<li><p>Known interactions are downloaded from <a class="reference external" href="https://www.ebi.ac.uk/intact/home">IntACT</a> and <a class="reference external" href="https://thebiogrid.org/">BioGRID</a></p></li>
<li><p>Protein data is downloaded from <a class="reference external" href="https://www.uniprot.org/">UniProt</a></p></li>
<li><p>Common contaminants are downloaded from <a class="reference external" href="https://thegpm.org/">Global proteome machine</a>, <a class="reference external" href="https://www.maxquant.org/">MaxQuant</a>, and a publication by Frankenfield et al., 2022 (PMID: 35793413).</p></li>
<li><p>MS-microscopy data is from a previous publication (PMID: 29568061)
Some are included in the files already.</p></li>
</ul>
</section>
<section id="build-the-main-docker-image">
<h5>Build the main docker image.<a class="headerlink" href="#build-the-main-docker-image" title="Link to this heading"></a></h5>
<p>!!NOTE!! docker commands in particular may require superuser rights (sudo).
This should take around 15 minutes, but can take much longer, mostly due to R requirements.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">build</span> <span class="o">-</span><span class="n">t</span> <span class="n">proteogyver</span><span class="p">:</span><span class="mf">1.0</span> <span class="o">-</span><span class="n">f</span> <span class="n">dockerfiles</span><span class="o">/</span><span class="n">dockerfile</span> <span class="o">.</span>
</pre></div>
</div>
<p>Next make sure that the paths specified in docker-compose.yaml exist. Modify docker-compose NOW to suit your local system if needed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">utils</span><span class="o">/</span><span class="n">check_volume_paths</span><span class="o">.</span><span class="n">sh</span> <span class="o">-</span><span class="n">v</span>
</pre></div>
</div>
<p>IF the script says that some paths are missing and you want to modify those, change them in the docker-compose.yaml. If the missing paths are OK, they can be created with –create switch:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">utils</span><span class="o">/</span><span class="n">check_volume_paths</span><span class="o">.</span><span class="n">sh</span> <span class="o">-</span><span class="n">v</span> <span class="o">--</span><span class="n">create</span>
</pre></div>
</div>
<p>For production use, the updater is required for external data to stay up to date. It is encouraged to run the updater script as a periodical service, and adjust the intervals between e.g. external updates via the parameters.toml file (see below). On the first, run, the updater will create a database, if one doesn’t yet exist. If you want to see what docker command the updater would run, run with –test flag (&gt;utils/run_updater.sh –test)</p>
<p>In order to have run annotations that are not parsed from the raw MS data files (see <a class="reference internal" href="#ms-run-data-pre-analysis"><span class="xref myst">MS run pre-analysis</span></a> ), an excel file CAN be supplied. The file name is specified in parameters.toml under “Database creation”.”MS runs information”.”Additional nfo excel”. Minimal example is supplied in this repo.
Building the updater container should take around a minute. Running the updater can take a long time, especially on the first run.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">build</span> <span class="o">-</span><span class="n">t</span> <span class="n">pg_updater</span><span class="p">:</span><span class="mf">1.0</span> <span class="o">-</span><span class="n">f</span> <span class="n">dockerfiles</span><span class="o">/</span><span class="n">dockerfile_updater</span> <span class="o">.</span>
<span class="n">utils</span><span class="o">/</span><span class="n">run_updater</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</section>
</section>
<section id="changing-parameters">
<h4>Changing parameters<a class="headerlink" href="#changing-parameters" title="Link to this heading"></a></h4>
<p>In order to keep the parameters.toml in sync with PG and the updater container, it is copied into path specified in the docker-compose.yaml. The file needs to be edited in that location ONLY, in order for the updated parameters to be applied to existing docker container, and the updater (e.g. different database name, or modified update intervals).</p>
</section>
<section id="run-the-container">
<h4>Run the container<a class="headerlink" href="#run-the-container" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Modify the dockerfiles/docker-compose.yaml file to suit your environment, and then deploy the container:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">compose</span> <span class="o">-</span><span class="n">f</span> <span class="n">dockerfiles</span><span class="o">/</span><span class="n">docker</span><span class="o">-</span><span class="n">compose</span><span class="o">.</span><span class="n">yaml</span> <span class="n">up</span>
</pre></div>
</div>
<section id="volume-paths">
<h5>Volume paths<a class="headerlink" href="#volume-paths" title="Link to this heading"></a></h5>
<p>PG will generate data on disk in the form of tempfiles when a dataset is requested for download, and when certain functions are used (e.g. imputation). As such, it is suggested that the cache folder (/proteogyver/cache) is mounted from e.g. tmpfs (/tmp on most linux distros) or similar, for speed and latency.</p>
<p>Database is suggested to live on an externally mounted directory due to size.</p>
<p>/data/Server_input should contain the MS_rundata directory, which houses .json files for MS runs that should be included in the database by the updater.
/data/Server_output currently has no use, but will in the future be used for larger exports.</p>
</section>
</section>
</section>
<section id="run-pg-locally-not-encouraged-but-possible">
<h3>Run PG locally (not encouraged, but possible)<a class="headerlink" href="#run-pg-locally-not-encouraged-but-possible" title="Link to this heading"></a></h3>
<p>Running PG locally is possible, especially for testing and development use. However, it is not a supported use case.
On a windows computer, it is recommended to use WSL. These instructions apply only to linux systems.</p>
<section id="requirements-and-setup">
<h4>Requirements and setup:<a class="headerlink" href="#requirements-and-setup" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>micromamba (or conda)</p></li>
<li><p>Python 3.10+</p></li>
<li><p>redis-cli</p></li>
<li><p>celery</p></li>
<li><p>SaintExpressSpc available in path</p></li>
</ul>
<p>First step is to adjust the parameters.toml file:</p>
<ul class="simple">
<li><p>Change “Data paths”.”Cache dir” to suit your local machin e (e.g. /tmp/pg_cache)</p></li>
<li><p>Change “Data paths.”Data import and export”: both paths need to be adjusted</p></li>
<li><p>Optional: Change “Config”.”Local debug” to true, if you encounter problems or are doing development and want to see error messages.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the PG environment and install dependencies (micromamba recommended)</span>
<span class="n">micromamba</span> <span class="n">create</span> <span class="o">-</span><span class="n">y</span> <span class="o">-</span><span class="n">n</span> <span class="n">PG</span> <span class="o">-</span><span class="n">f</span> <span class="n">app</span><span class="o">/</span><span class="n">requirements</span><span class="o">/</span><span class="n">environment</span><span class="o">.</span><span class="n">yml</span>
<span class="c1"># Generate a database. This can take a while.</span>
<span class="n">micromamba</span> <span class="n">run</span> <span class="o">-</span><span class="n">n</span> <span class="n">PG</span> <span class="n">python</span> <span class="n">database_admin</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section id="run-pg">
<h4>Run PG:<a class="headerlink" href="#run-pg" title="Link to this heading"></a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">micromamba</span> <span class="n">run</span> <span class="o">-</span><span class="n">n</span> <span class="n">PG</span> <span class="n">bash</span> <span class="n">startup</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="updating-the-database">
<h2>Updating the database<a class="headerlink" href="#updating-the-database" title="Link to this heading"></a></h2>
<p>To update the database, use the updater container, preferably with the included script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">utils</span><span class="o">/</span><span class="n">run_updater</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>On the first run, it will create a new database file in the specified db directory (specified in parameters.toml), if the file does not exist. In other cases, it will update the existing database. For updates, data will be added to existing tables from the update files directory (specified in parameters.toml). If it does not exist, the updater will create it, as well as example files for each database table. Crapome and control set table examples will not be created, because they would clutter up the output. For each of these tables, lines in them represent either new data rows, or modifications to existing rows. Deletions are handled differently, and are described below.</p>
<p>IF the files handed to updater contain columns, that are not in the existing tables, the updater will add them. However, the column names will be sanitized to only contain lowercase letters, numbers, and underscores, and any consecutive underscores will be removed. E.g. “gene name” will be changed to “gene_name”. If a column starts with a number, “c” will be added to the beginning of the name. E.g. “1.2.3” will be changed to “c1_2_3”.</p>
<p>When updating existing entries in the database, if the update file does not contain a column that is present in the database, or a row of the update file has no value for a column,the updater will impute values from the existing entries in the database.</p>
<p>Keep in mind that the updater will delete the files from the db_updates directories after it has finished running.</p>
<section id="update-running-order">
<h3>Update running order:<a class="headerlink" href="#update-running-order" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p>External data is updated first.</p></li>
<li><p>Deletions are handled next.</p></li>
<li><p>Additions and replacements are handled next.</p></li>
<li><p>Finally other modifications are applied.</p></li>
</ol>
<p>If the tools that provide the external data provide ANY new columns that do not already exist in the database, the new columns will need to be manually added to the database FIRST. Otherwise the updater will throw an error.</p>
</section>
<section id="adding-ms-run-data">
<h3>Adding MS run data<a class="headerlink" href="#adding-ms-run-data" title="Link to this heading"></a></h3>
<p>See <a class="reference internal" href="#ms-run-data-pre-analysis"><span class="xref myst">MS run data pre-analysis</span></a> section of the install instructions.</p>
</section>
<section id="adding-new-crapome-or-control-sets">
<h3>Adding new crapome or control sets:<a class="headerlink" href="#adding-new-crapome-or-control-sets" title="Link to this heading"></a></h3>
<p>Two files per set are needed:</p>
<ol class="arabic simple">
<li><p>The crapome/control overall table needs an update, and for that the control_sets.tsv or crapome_sets.tsv example file can be added to, and then put into the db_updates/crapome_sets or db_updates/control_sets directory.</p></li>
<li><p>The individual crapome/control set needs its own update file added to the db_updates/add_or_replace directory. The file should have the same columns, as existing crapome/control set tables (specified in parameters.toml at “database creation”.”control and crapome db detailed columns”). The column types can be found in “database creation”.”control and crapome db detailed types”.</p></li>
</ol>
</section>
<section id="adding-other-new-tables">
<h3>Adding other new tables:<a class="headerlink" href="#adding-other-new-tables" title="Link to this heading"></a></h3>
<p>In order to add any other new tables, two updates and two files are needed:</p>
<ol class="arabic simple">
<li><p>.tsv file in the “add_or_replace” directory. Column names MUST NOT contain any spaces. Otherwise the updater will throw an error.</p></li>
<li><p>.txt file in the “add_or_replace” directory with the exact same name as the .tsv file, except it MUST have a .txt extension. This file contains the column types for the new table. One line per column, in the same order as the columns in the .tsv file. It should contain only the types. For example, if the .tsv file has the following columns: “uniprot_id”, “gene_name”, “description”, “spectral_count”, the .txt file should have the following lines: “TEXT PRIMARY KEY”, “TEXT”, “TEXT”, “INTEGER”. Empty lines and lines starting with ‘#’ are ignored.</p></li>
<li><p>The new table needs to be added to the [“Database updater”.”Update files”] list with the same name as the .tsv file, but without the .tsv extension.</p></li>
<li><p>In order to generate an empty template file for future updates, the [“Database updater”.”Database table primary keys”] list in parameters.toml needs to be added to.</p></li>
</ol>
</section>
<section id="deleting-data">
<h3>Deleting data<a class="headerlink" href="#deleting-data" title="Link to this heading"></a></h3>
<p>To delete data rows, the syntax is different. Each file in the remove_data -directory should be named exactly the same as the table it is deleting from + .tsv. E.g. to delete from table “proteins”, name the file proteins.tsv. One row should contain one criteria in the format of “column_name, value\tcolumn_name2, value2”, without quotes. The tab separates criterias from one another, and all criteria of a row will have to match for the deletion. E.g.
uniprot_id, UPID1\tgene_name, GENE12
will match the rows in the database where uniprot_id is UPID1 and gene_name is GENE12.</p>
<p>Empty lines and lines starting with ‘#’ are ignored.</p>
<p>Deleting columns from tables is not supported this way, nor is deleting entire tables. These need to be done manually. The database is sqlite3, and thus easy to work with. Please make a backup first.</p>
</section>
<section id="update-logging">
<h3>Update logging<a class="headerlink" href="#update-logging" title="Link to this heading"></a></h3>
<p>Updates will be logged to the update_log table.</p>
</section>
</section>
<section id="rare-use-cases">
<h2>Rare use cases<a class="headerlink" href="#rare-use-cases" title="Link to this heading"></a></h2>
<section id="embedding-other-websites-as-tabs-within-proteogyver">
<h3>Embedding other websites as tabs within Proteogyver<a class="headerlink" href="#embedding-other-websites-as-tabs-within-proteogyver" title="Link to this heading"></a></h3>
<p>To embed another website/tool within Proteogyver, add a line to embed_pages.tsv, and run the embedded_page_updater.py script. Preferably these will be things hosted on the same server, but this is not required. Current example is proteomics.fi (hosted externally). Keep in mind that most websites ban browsers from accessing if they are embedded in an html.Embed element.</p>
</section>
<section id="adding-custom-tools-as-tabs-to-proteogyver">
<h3>Adding custom tools as tabs to Proteogyver<a class="headerlink" href="#adding-custom-tools-as-tabs-to-proteogyver" title="Link to this heading"></a></h3>
<p>Adding custom tools to Proteogyver is supported as pages in the app/pages folder. Here the following rules should be followed:</p>
<ul class="simple">
<li><p>Use dash.register_page to register the page (register_page(<strong>name</strong>, path=’/YOUR_PAGE_NAME’) )</p></li>
<li><p>Use GENERIC_PAGE from element_styles.py for styling starting point. Mostly required from this is the offset on top of the page to fit the navbar</p></li>
</ul>
</section>
<section id="accessing-the-database-from-other-tools">
<h3>Accessing the database from other tools<a class="headerlink" href="#accessing-the-database-from-other-tools" title="Link to this heading"></a></h3>
<p>Other tools can access the database. Writes to the database should not require any specific precautions. However, please check that the database is not locked, and another transaction is not in progress. Other scenarios when one should not write to the database include if it is in the process of being backed up, or while the updater is actively running.</p>
</section>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Link to this heading"></a></h2>
<p>If you use Proteogyver or a part of it in your research, please cite:
[Add citation information here]</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>