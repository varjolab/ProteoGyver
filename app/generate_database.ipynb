{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962715f-5826-4962-a14c-dcd28a3e6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from plotly import graph_objects as go\n",
    "from plotly import io as pio\n",
    "from components import text_handling\n",
    "import xmltodict\n",
    "from components.api_tools.annotation import intact\n",
    "from components.api_tools.annotation import biogrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f708f09-59fb-41cc-a588-61fddd9d9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join('data_assets','db build files')\n",
    "dbdir = 'data'\n",
    "crapome = pd.read_csv(os.path.join(datadir,'crapome table.tsv'),sep='\\t')\n",
    "controls = pd.read_csv(os.path.join(datadir,'control table.tsv'),sep='\\t')\n",
    "jsons = {}\n",
    "for f in os.listdir(datadir):\n",
    "    if f.split('.')[-1]=='json':\n",
    "        with open(os.path.join(datadir,f)) as fil:\n",
    "            jsons[f'data_{f}'] = json.load(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e41d0f-8940-4535-a0a9-434bb15c2c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROTID</th>\n",
       "      <th>AP_GFP_C_1_S2-A2_1_6530</th>\n",
       "      <th>AP_GFP_C_2_S2-A3_1_6531</th>\n",
       "      <th>AP_GFP_C_3_S2-A4_1_6532</th>\n",
       "      <th>AP_GFP_MED_NLS_1_S2-B2_1_6542</th>\n",
       "      <th>AP_GFP_MED_NLS_2_S2-B3_1_6543</th>\n",
       "      <th>AP_GFP_MED_NLS_3_S2-B4_1_6544</th>\n",
       "      <th>AP_GFP_MYC_NLS_1_S2-B6_1_6546</th>\n",
       "      <th>AP_GFP_MYC_NLS_2_S2-B7_1_6547</th>\n",
       "      <th>AP_GFP_MYC_NLS_3_S2-B8_1_6548</th>\n",
       "      <th>...</th>\n",
       "      <th>SUC_N_GFP_BIO10_S1-C2_1_4443</th>\n",
       "      <th>SUC_N_GFP_BIO1_S3-H1_1_3637</th>\n",
       "      <th>SUC_N_GFP_BIO2_S3-H2_1_3638</th>\n",
       "      <th>SUC_N_GFP_BIO3_S3-H3_1_3639</th>\n",
       "      <th>SUC_N_GFP_BIO4_S3-H4_1_3640</th>\n",
       "      <th>SUC_N_GFP_BIO5_S3-H5_1_3641</th>\n",
       "      <th>SUC_N_GFP_BIO6_S3-H6_1_3642</th>\n",
       "      <th>SUC_N_GFP_BIO7_S3-H7_1_3643</th>\n",
       "      <th>SUC_N_GFP_BIO8_S3-H8_1_3644</th>\n",
       "      <th>SUC_N_GFP_BIO9_S1-C1_1_4442</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A075B6H7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0A0MS14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4J1V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0B4J1V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0B4J2D5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PROTID  AP_GFP_C_1_S2-A2_1_6530  AP_GFP_C_2_S2-A3_1_6531  \\\n",
       "0  A0A075B6H7                      NaN                      NaN   \n",
       "1  A0A0A0MS14                      NaN                      NaN   \n",
       "2  A0A0B4J1V0                      NaN                      NaN   \n",
       "3  A0A0B4J1V1                      NaN                      NaN   \n",
       "4  A0A0B4J2D5                      6.0                      5.0   \n",
       "\n",
       "   AP_GFP_C_3_S2-A4_1_6532  AP_GFP_MED_NLS_1_S2-B2_1_6542  \\\n",
       "0                      NaN                            NaN   \n",
       "1                      NaN                            NaN   \n",
       "2                      NaN                            NaN   \n",
       "3                      NaN                            NaN   \n",
       "4                      7.0                            NaN   \n",
       "\n",
       "   AP_GFP_MED_NLS_2_S2-B3_1_6543  AP_GFP_MED_NLS_3_S2-B4_1_6544  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            1.0   \n",
       "\n",
       "   AP_GFP_MYC_NLS_1_S2-B6_1_6546  AP_GFP_MYC_NLS_2_S2-B7_1_6547  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            7.0                            5.0   \n",
       "\n",
       "   AP_GFP_MYC_NLS_3_S2-B8_1_6548  ...  SUC_N_GFP_BIO10_S1-C2_1_4443  \\\n",
       "0                            NaN  ...                           NaN   \n",
       "1                            NaN  ...                           NaN   \n",
       "2                            NaN  ...                           NaN   \n",
       "3                            NaN  ...                           NaN   \n",
       "4                            5.0  ...                           NaN   \n",
       "\n",
       "   SUC_N_GFP_BIO1_S3-H1_1_3637  SUC_N_GFP_BIO2_S3-H2_1_3638  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   SUC_N_GFP_BIO3_S3-H3_1_3639  SUC_N_GFP_BIO4_S3-H4_1_3640  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   SUC_N_GFP_BIO5_S3-H5_1_3641  SUC_N_GFP_BIO6_S3-H6_1_3642  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   SUC_N_GFP_BIO7_S3-H7_1_3643  SUC_N_GFP_BIO8_S3-H8_1_3644  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   SUC_N_GFP_BIO9_S1-C1_1_4442  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea77eaf-21b4-436b-b44f-5ce10c21756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'VL GFP MAC3 AP': [\n",
    "             'VL GFP MAC3-N AP-MS',\n",
    "    ],\n",
    "    'VL GFP MAC3 BioID': [\n",
    "             'VL GFP MAC3-N BioID'\n",
    "    ],\n",
    "    'VL GFP MAC2 AP': [\n",
    "             'VL GFP MAC2-C AP-MS',\n",
    "             'VL GFP MAC2-N AP-MS',\n",
    "    ],\n",
    "    'VL GFP MAC2 BioID': [\n",
    "             'VL GFP MAC2-C BioID',\n",
    "             'VL GFP MAC2-N BioID'\n",
    "    ],\n",
    "    'VL GFP MAC AP': [\n",
    "            'VL GFP MAC-C AP-MS',\n",
    "            'VL GFP MAC-N AP-MS',\n",
    "    ],\n",
    "    'VL GFP MAC AP NLS': [\n",
    "            'VL GFP MAC-MED-NLS AP-MS',\n",
    "            'VL GFP MAC-MYC-NLS AP-MS',\n",
    "            'VL GFP MAC-NLS AP-MS',\n",
    "    ],\n",
    "    'VL GFP MAC BioID': [\n",
    "            'VL GFP MAC-C BioID',\n",
    "            'VL GFP MAC-N BioID'\n",
    "    ],\n",
    "    'VL GFP MAC BioID NLS': [\n",
    "            'VL GFP MAC-MED-NLS BioID',\n",
    "            'VL GFP MAC-MYC-NLS BioID',\n",
    "            'VL GFP MAC-NLS BioID'\n",
    "    ],\n",
    "    'Nesvilab': ['nesvilab']\n",
    "}\n",
    "crapome_tables = {}\n",
    "columns = [\n",
    "    'protein_id',\n",
    "    'identified_in',\n",
    "    'frequency',\n",
    "    'spc_sum',\n",
    "    'spc_avg',\n",
    "    'spc_min',\n",
    "    'spc_max',\n",
    "    'spc_stdev']\n",
    "types = [\n",
    "    'TEXT PRIMARY KEY',\n",
    "    'INTEGER NOT NULL',\n",
    "    'REAL NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'REAL NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'REAL NOT NULL'\n",
    "]\n",
    "crapome_entries = []\n",
    "for setname, setcols in sets.items():\n",
    "    all_cols = ['PROTID']\n",
    "    defa = 1\n",
    "    if 'MAC2' in setname: defa = 0 # default enabled value\n",
    "    tablename = f'crapome_{setname}'.lower().replace(' ','_')\n",
    "    for sc in setcols:\n",
    "        all_cols.extend(jsons['data_crapome sets.json'][sc])\n",
    "    all_cols = sorted(list(set(all_cols)))\n",
    "    set_df = crapome[all_cols]\n",
    "    setname = f'{setname} ({len(all_cols)} runs)'\n",
    "    set_df.index = set_df['PROTID']\n",
    "    set_df = set_df.drop(columns=['PROTID']).replace(0,np.nan).dropna(how='all',axis=0).dropna(how='all',axis=1)\n",
    "    nruns = set_df.shape[1]\n",
    "    set_data = []\n",
    "    for protid, row in set_df.iterrows():\n",
    "        stdval = row.std()\n",
    "        if pd.isna(stdval):\n",
    "            stdval = -1\n",
    "        set_data.append([protid, row.notna().sum(), row.notna().sum()/nruns,row.sum(), row.mean(), row.min(), row.max(), stdval])\n",
    "    crapome_tables[tablename] = pd.DataFrame(columns=columns, data=set_data)\n",
    "    crapome_entries.append([tablename, setname, nruns, 0, defa, tablename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaac03-74ac-4b92-87dd-5d3ed3d6624f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc12b865-b834-4dac-ae21-bb37c10e8ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control: 74150\n"
     ]
    }
   ],
   "source": [
    "control_tables = {}\n",
    "control_entries = []\n",
    "for setname, setcols in sets.items():\n",
    "    if setname == 'Nesvilab': continue\n",
    "    all_cols = ['PROTID']\n",
    "    defa = 1\n",
    "    if 'MAC2' in setname: defa = 0\n",
    "    tablename = f'control_{setname}'.lower().replace(' ','_')\n",
    "    for sc in setcols:\n",
    "        all_cols.extend(jsons['data_control sets.json'][sc])\n",
    "    all_cols = sorted(list(set(all_cols)))\n",
    "    setname = f'{setname} ({len(all_cols)} runs)'\n",
    "    set_df = controls[all_cols]\n",
    "    set_df.index = set_df['PROTID']\n",
    "    set_df = set_df.drop(columns=['PROTID']).replace(0,np.nan).dropna(how='all',axis=0).dropna(how='all',axis=1)\n",
    "    nruns = set_df.shape[1]\n",
    "    set_data = []\n",
    "    for protid, row in set_df.iterrows():\n",
    "        stdval = row.std()\n",
    "        if pd.isna(stdval):\n",
    "            stdval = -1\n",
    "        set_data.append([protid, row.notna().sum(), row.notna().sum()/nruns,row.sum(), row.mean(), row.min(), row.max(), stdval])\n",
    "    control_tables[tablename] = (set_df, pd.DataFrame(columns=columns, data=set_data))\n",
    "    control_entries.append([tablename, setname, nruns, 0, defa, tablename])\n",
    "\n",
    "control_cols = ['control_set','control_set_name','runs','is_disabled','is_default','control_table_name']\n",
    "crapome_cols = ['crapome_set','crapome_set_name','runs','is_disabled','is_default','crapome_table_name']\n",
    "exts = ['TEXT PRIMARY KEY','TEXT NOT NULL','INTEGER NOT NULL','INTEGER NOT NULL','INTEGER NOT NULL','TEXT NOT NULL']\n",
    "\n",
    "control_table_str =  [\n",
    "        f'CREATE TABLE control_sets (',\n",
    "    ]\n",
    "for i, c in enumerate(control_cols):\n",
    "    control_table_str.append(f'    {c} {exts[i]},',)\n",
    "control_table_str = '\\n'.join(control_table_str).strip(',')\n",
    "control_table_str += '\\n);'\n",
    "\n",
    "crapome_table_str =  [\n",
    "        f'CREATE TABLE crapome_sets (',\n",
    "    ]\n",
    "for i, c in enumerate(crapome_cols):\n",
    "    crapome_table_str.append(f'    {c} {exts[i]},',)\n",
    "crapome_table_str = '\\n'.join(crapome_table_str).strip(',')\n",
    "crapome_table_str += '\\n);'\n",
    "\n",
    "prot_cols = [\n",
    "    'uniprot_id',\n",
    "    'is_reviewed',\n",
    "    'gene_name',\n",
    "    'entry_name',\n",
    "    'all_gene_names',\n",
    "    'organism',\n",
    "    'length',\n",
    "    'sequence',\n",
    "    'is_latest',\n",
    "    'entry_source',\n",
    "    'update_time'\n",
    "]\n",
    "prot_exts = [\n",
    "    'TEXT PRIMARY KEY',\n",
    "    'INTEGER NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL'\n",
    "]\n",
    "\n",
    "prot_table_str =  [\n",
    "        f'CREATE TABLE proteins (',\n",
    "    ]\n",
    "for i, c in enumerate(prot_cols):\n",
    "    prot_table_str.append(f'    {c} {prot_exts[i]},',)\n",
    "prot_table_str = '\\n'.join(prot_table_str).strip(',')\n",
    "prot_table_str += '\\n);'\n",
    "\n",
    "table_create_sql = [control_table_str, crapome_table_str, prot_table_str]\n",
    "\n",
    "insert_sql = []\n",
    "\n",
    "for vals in control_entries:\n",
    "    tablename = vals[0]\n",
    "    detailed, overall = control_tables[tablename]\n",
    "    detailed.rename(\n",
    "        columns={\n",
    "            c: 'CS_'+text_handling.replace_accent_and_special_characters(c,'_')\n",
    "            for c in detailed.columns\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    create_str = [\n",
    "        f'CREATE TABLE {tablename}_overall (',\n",
    "    ]\n",
    "    for i, c in enumerate(overall.columns):\n",
    "        create_str.append(f'    {c} {types[i]},',)\n",
    "    create_str = '\\n'.join(create_str).strip(',')\n",
    "    create_str += '\\n);'\n",
    "    table_create_sql.append(create_str)\n",
    "    add_str = [f'INSERT INTO control_sets ({\", \".join(control_cols)}) VALUES ({\", \".join([\"?\" for _ in control_cols])})', vals]\n",
    "    insert_sql.append(add_str)\n",
    "    for _, row in overall.iterrows():\n",
    "        add_str = [f'INSERT INTO {tablename}_overall ({\", \".join(overall.columns)}) VALUES ({\", \".join([\"?\" for _ in overall.columns])})', tuple(row.values)]\n",
    "        insert_sql.append(add_str)\n",
    "    create_str = [\n",
    "        f'CREATE TABLE {tablename} (',\n",
    "    ]\n",
    "    detailed = detailed.reset_index()\n",
    "    detailed_control_types = ['TEXT PRIMARY KEY']\n",
    "    for c in detailed.columns[1:]:\n",
    "        detailed_control_types.append('REAL')\n",
    "    for i, c in enumerate(detailed.columns):\n",
    "        create_str.append(f'    {c} {detailed_control_types[i]},',)\n",
    "    create_str = '\\n'.join(create_str).strip(',')\n",
    "    create_str += '\\n);'\n",
    "    table_create_sql.append(create_str)\n",
    "    for _, row in detailed.iterrows():\n",
    "        add_str = [f'INSERT INTO {tablename} ({\", \".join(detailed.columns)}) VALUES ({\", \".join([\"?\" for _ in detailed.columns])})', tuple(row.values)]\n",
    "        insert_sql.append(add_str)\n",
    "print('control:', len(insert_sql))\n",
    "\n",
    "for vals in crapome_entries:\n",
    "    tablename = vals[0]\n",
    "    create_str = [\n",
    "        f'CREATE TABLE {tablename} (',\n",
    "    ]\n",
    "    for i, c in enumerate(columns):\n",
    "        create_str.append(f'    {c} {types[i]},',)\n",
    "    create_str = '\\n'.join(create_str).strip(',')\n",
    "    create_str += '\\n);'\n",
    "    table_create_sql.append(create_str)\n",
    "    add_str = [f'INSERT INTO crapome_sets ({\", \".join(crapome_cols)}) VALUES({\", \".join([\"?\" for _ in crapome_cols])})', vals]\n",
    "    insert_sql.append(add_str)\n",
    "    for _, row in crapome_tables[tablename].iterrows():\n",
    "        add_str = [f'INSERT INTO {tablename} ({\", \".join(columns)}) VALUES ({\", \".join([\"?\" for _ in columns])})', tuple(row.values)]\n",
    "        insert_sql.append(add_str)\n",
    "print('crapome:',len(insert_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d57b37-8909-489f-ac95-c88905fb9e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein: 711646\n"
     ]
    }
   ],
   "source": [
    "uniprot_df = pd.read_csv(os.path.join(datadir,'uniprotkb_AND_reviewed_true_2023_09_04.tsv'),sep='\\t',index_col = 'Entry')\n",
    "uniprots = set(uniprot_df.index.values)\n",
    "for protid, row in uniprot_df.iterrows():\n",
    "    gn = row['Gene Names (primary)']\n",
    "    if pd.isna(gn):\n",
    "        gn = row['Entry Name']\n",
    "    gns = row['Gene Names']\n",
    "    if pd.isna(gns):\n",
    "        gns = row['Entry Name']\n",
    "    row = row.fillna('')\n",
    "    data = [\n",
    "        protid,\n",
    "        int(row['Reviewed']=='reviewed'),\n",
    "        gn,\n",
    "        row['Entry Name'],\n",
    "        gns,\n",
    "        row['Organism'],\n",
    "        row['Length'],\n",
    "        row['Sequence'],\n",
    "        1,\n",
    "        'uniprot_initial_download',\n",
    "        datetime.today().strftime('%Y-%m-%d')\n",
    "    ]\n",
    "    add_str = f'INSERT INTO proteins ({\", \".join(prot_cols)}) VALUES ({\", \".join([\"?\" for _ in prot_cols])})'\n",
    "    insert_sql.append([add_str, data])\n",
    "print('protein:', len(insert_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150fb31f-f266-4220-85f2-2b4b2309423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contaminants: 712093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cont_cols = [\n",
    "    'uniprot_id',\n",
    "    'is_reviewed',\n",
    "    'gene_name',\n",
    "    'entry_name',\n",
    "    'all_gene_names',\n",
    "    'organism',\n",
    "    'length',\n",
    "    'sequence',\n",
    "    'entry_source',\n",
    "    'contamination_source',\n",
    "    'update_time'\n",
    "]\n",
    "cont_exts = [\n",
    "    'TEXT PRIMARY KEY',\n",
    "    'INTEGER NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'INTEGER NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL',\n",
    "    'TEXT NOT NULL'\n",
    "]\n",
    "\n",
    "conts = pd.read_csv(os.path.join(datadir,'contaminant_list.tsv'),sep='\\t')\n",
    "conts = conts[~conts['Uniprot ID'].isin(['P0C1U8','Q2FZL2'])]\n",
    "dd = pd.read_csv(os.path.join(datadir,'idmapping_2023_09_11.tsv'),sep='\\t')\n",
    "for _,row in dd.iterrows():\n",
    "    conts.loc[conts[conts['Uniprot ID']==row['Entry']].index,'Length'] = row['Length']\n",
    "dd2 = pd.read_csv(os.path.join(datadir,'idmapping_2023_09_121.tsv'),sep='\\t')\n",
    "for _, row in dd2.iterrows():\n",
    "    ctloc = conts[conts['Uniprot ID']==row['From']]\n",
    "    conts.loc[ctloc.index, 'Sequence'] = row['Sequence']\n",
    "    conts.loc[ctloc.index, 'Gene names'] = row['Gene Names']\n",
    "    conts.loc[ctloc.index, 'Length'] = row['Length']\n",
    "    conts.loc[ctloc.index, 'Status'] = row['Reviewed']\n",
    "\n",
    "seqs = {entry: row['Sequence'] for entry, row in uniprot_df.iterrows()}\n",
    "seq_col = []\n",
    "for _,row in conts.iterrows():\n",
    "    if row['Uniprot ID'] not in seqs:\n",
    "        seq_col.append('')\n",
    "    else:\n",
    "        seq_col.append(seqs[row['Uniprot ID']])\n",
    "conts['Sequence'] = seq_col\n",
    "conts['Length'] = conts['Length'].fillna(1).astype(int)\n",
    "for i, row in conts[conts['Gene names'].isna()].iterrows():\n",
    "    conts.loc[i, 'Gene names'] = f'{row[\"Protein names\"]}({row[\"Uniprot ID\"]})'\n",
    "conts['Organism'] = conts['Organism'].fillna('None')\n",
    "conts['Sequence'] = conts['Sequence'].fillna('Unknown')\n",
    "conts['Sequence'] = conts['Sequence'].fillna('Unknown')\n",
    "conts['Source of Contamination'] = conts['Source of Contamination'].fillna('Unspecified')\n",
    "cont_table_str =  [\n",
    "    f'CREATE TABLE contaminants (',\n",
    "]\n",
    "for i, c in enumerate(cont_cols):\n",
    "    cont_table_str.append(f'    {c} {cont_exts[i]},',)\n",
    "cont_table_str = '\\n'.join(cont_table_str).strip(',')\n",
    "cont_table_str += '\\n);'\n",
    "for _, row in conts.iterrows():\n",
    "    gn = row['Gene names']\n",
    "    if not 'Uncharac' in gn:\n",
    "        gn = gn.split()[0]\n",
    "    gns = row['Gene names']\n",
    "    data = [\n",
    "        row['Uniprot ID'],\n",
    "        int(row['Status']=='reviewed'),\n",
    "        gn,\n",
    "        row['Entry name'],\n",
    "        gns,\n",
    "        row['Organism'],\n",
    "        row['Length'],\n",
    "        row['Sequence'],\n",
    "        row['DataBase'],\n",
    "        row['Source of Contamination'],\n",
    "        datetime.today().strftime('%Y-%m-%d')\n",
    "    ]\n",
    "    add_str = f'INSERT INTO contaminants ({\", \".join(cont_cols)}) VALUES ({\", \".join([\"?\" for _ in cont_cols])})'\n",
    "    insert_sql.append([add_str, data])\n",
    "table_create_sql.append(cont_table_str)\n",
    "print('contaminants:',len(insert_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5508bcd7-6134-4676-b4fa-3afbf9f3f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tictable_create = ['CREATE TABLE IF NOT EXISTS ms_runs (']\n",
    "tic_cols = [\n",
    "    'run_id TEXT PRIMARY KEY',\n",
    "    'sample_name TEXT NOT NULL',\n",
    "    'run_name TEXT NOT NULL',\n",
    "    'run_time TEXT NOT NULL',\n",
    "    'instrument TEXT NOT NULL',\n",
    "    'author TEXT NOT NULL',\n",
    "    'sample_type TEXT NOT NULL',\n",
    "    'run_type TEXT NOT NULL',\n",
    "    'lc_method TEXT NOT NULL',\n",
    "    'ms_method TEXT NOT NULL',\n",
    "    'bait TEXT',\n",
    "    'bait_uniprot TEXT',\n",
    "    'chromatogram_max_time INTEGER NOT NULL',\n",
    "    'cell_line TEXT',\n",
    "    'project TEXT',\n",
    "    'author_notes TEXT',\n",
    "    'bait_tag TEXT',\n",
    "]\n",
    "for col in tic_cols:\n",
    "    tictable_create.append(f'    {col},')\n",
    "for col in  [\n",
    "        'auc REAL NOT NULL',\n",
    "        'intercepts INTEGER NOT NULL',\n",
    "        'avg_peaks_per_timepoint REAL NOT NULL',\n",
    "        'mean_intensity INTEGER NOT NULL',\n",
    "        'max_intensity INTEGER NOT NULL',\n",
    "        'json TEXT NOT NULL',\n",
    "        'trace TEXT NOT NULL',\n",
    "    ]:\n",
    "    tic_cols.extend([\n",
    "        f'bpc_{col}',\n",
    "        f'msn_{col}',\n",
    "        f'tic_{col}'\n",
    "    ])\n",
    "    tictable_create.extend([f'    {c},' for c in tic_cols[-3:]])\n",
    "tictable_create = '\\n'.join(tictable_create).strip(',')\n",
    "tictable_create += '\\n);'\n",
    "table_create_sql.append(tictable_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c8963-ed4d-4207-a5d4-180bdb9dfe7f",
   "metadata": {},
   "source": [
    "## Run the dig_tic.py script at this point from an account with access to .d storage folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f056039-d5f7-4cc8-aa92-753db7294b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for typ in ['BPC','TIC','MSn']:\n",
    "    for key in ['auc','intercepts','peaks_per_timepoint','mean_intensity','max_intensity', 'json','trace', 'intercept_json']:\n",
    "        new_cols.append(f'{typ}_{key}')\n",
    "col_renames = {c: c.replace('peaks_per_timepoint','avg_peaks_per_timepoint') for c in new_cols}\n",
    "tic_dir = os.path.join('data_assets','TIC data')\n",
    "tic_data_files = [os.path.join(tic_dir, f) for f in os.listdir(tic_dir) if 'TIC data_' in f]\n",
    "tic_data = pd.concat([pd.read_csv(f,sep='\\t') for f in tic_data_files]).drop(columns='Unnamed: 0')\n",
    "new_data = [[] for _ in new_cols]\n",
    "for _,row in tic_data.iterrows():\n",
    "    dic = json.loads(row['chromatograms'])\n",
    "    if len(dic['json'].keys()) == 0:\n",
    "        for i, nc in enumerate(new_cols):\n",
    "            new_data[i].append(np.nan)\n",
    "    else:\n",
    "        for i, nc in enumerate(new_cols):\n",
    "            typ, key = nc.split('_',maxsplit=1)\n",
    "            new_data[i].append(dic[key][typ])\n",
    "for i, nc in enumerate(new_cols):\n",
    "    tic_data[nc] = new_data[i]\n",
    "if not 'chromatogram_max_time' in tic_data.columns:\n",
    "    tvals = []\n",
    "    for _,row in tic_data.iterrows():\n",
    "        tvals.append(pd.Series(row['BPC_json']).index.max())\n",
    "    tic_data['chromatogram_max_time'] = tvals\n",
    "dic_cols = [c for c in tic_data.columns if 'json' in c]\n",
    "for d in dic_cols:\n",
    "    nvals = [json.dumps(v) if type(v) is dict else str(v).replace('nan','') for v in tic_data[d].values]\n",
    "    tic_data[d] = nvals\n",
    "tic_data = tic_data.rename(columns=col_renames)\n",
    "tic_data = tic_data.rename(columns={\n",
    "    c: c.lower() for c in tic_data.columns\n",
    "})\n",
    "tic_data = tic_data.rename(columns={\n",
    "    'sample_id': 'run_id', 'datafolder_name': 'run_name','HyStar_LC_Method_Name'.lower(): 'lc_method', 'HyStar_MS_Method_Name'.lower(): 'ms_method'\n",
    "})\n",
    "tic_data['instrument'] = 'timsTOF pro 2'\n",
    "tic_data['run_id'] = tic_data['run_id'].astype(int)\n",
    "runlist = pd.read_excel(os.path.join('..','..','..','combined runlist.xlsx'))\n",
    "nvals = {c: [] for c in [r for r in tic_cols if r.split()[0] not in tic_data.columns]}\n",
    "for _,row in tic_data.iterrows():\n",
    "    run = runlist[runlist['Raw file']==row['run_name']]\n",
    "    if run.shape[0]==0:\n",
    "        for key in nvals.keys():\n",
    "            nvals[key].append('')\n",
    "    else:\n",
    "        run = run.iloc[0]\n",
    "        nvals['author TEXT NOT NULL'].append(run['Who'])\n",
    "        nvals['sample_type TEXT NOT NULL'].append(run['Sample type'])\n",
    "        nvals['run_type TEXT NOT NULL'].append(run['Run type'])\n",
    "        nvals['cell_line TEXT'].append(run['Cell line / material'])\n",
    "        nvals['project TEXT'].append(run['Project'])\n",
    "        nvals['author_notes TEXT'].append(run['Notes'])\n",
    "        nvals['bait_tag TEXT'].append(run['tag'])\n",
    "        nvals['bait TEXT'].append(run['Bait / other uniprot or ID'])\n",
    "        if run['Bait / other uniprot or ID'] in uniprots:\n",
    "            nvals['bait_uniprot TEXT'].append(run['Bait / other uniprot or ID'])\n",
    "        else:\n",
    "            nvals['bait_uniprot TEXT'].append('')\n",
    "for c, vals in nvals.items():\n",
    "    tic_data[c.split()[0]] = vals\n",
    "tic_data = tic_data[tic_data['chromatogram_max_time']!='']\n",
    "tic_data = tic_data[tic_data['chromatogram_max_time']!=0]\n",
    "tic_data = tic_data[tic_data['chromatogram_max_time'].notna()]\n",
    "tic_data = tic_data.drop_duplicates()\n",
    "print(len(insert_sql))\n",
    "for _,row in tic_data.iterrows():\n",
    "    data = [\n",
    "        row[c.split()[0]] for c in tic_cols\n",
    "    ]\n",
    "    add_str = f'INSERT INTO ms_runs ({\", \".join([c.split()[0] for c in tic_cols])}) VALUES ({\", \".join([\"?\" for _ in tic_cols])})'\n",
    "    insert_sql.append([add_str, data])\n",
    "print(len(insert_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66732d6e-9a58-49b1-963b-19c6272f8d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m merg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pm\n\u001b[1;32m     49\u001b[0m merg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m npubs\n\u001b[0;32m---> 51\u001b[0m int_df_slim \u001b[38;5;241m=\u001b[39m merg[merg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniprot_id_a\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43mprot\u001b[49m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;241m&\u001b[39m merg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniprot_id_b\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(prot\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prot' is not defined"
     ]
    }
   ],
   "source": [
    "inttable_create = ['CREATE TABLE IF NOT EXISTS known_interactions (']\n",
    "inttable_cols = [\n",
    "    'interaction TEXT PRIMARY KEY',\n",
    "    'uniprot_id_a TEXT NOT NULL',\n",
    "    'uniprot_id_b TEXT NOT NULL',\n",
    "    'uniprot_id_a_noiso TEXT NOT NULL',\n",
    "    'uniprot_id_b_noiso TEXT NOT NULL',\n",
    "    'source_database TEXT NOT NULL',\n",
    "    'isoform_a TEXT',\n",
    "    'isoform_b TEXT',\n",
    "    'experimental_role_interactor_a TEXT',\n",
    "    'interaction_detection_method TEXT',\n",
    "    'publication_identifier TEXT',\n",
    "    'biological_role_interactor_b TEXT',\n",
    "    'annotation_interactor_a TEXT',\n",
    "    'confidence_value TEXT',\n",
    "    'interaction_type TEXT',\n",
    "    'experimental_role_interactor_b TEXT',\n",
    "    'annotation_interactor_b TEXT',\n",
    "    'biological_role_interactor_a TEXT',\n",
    "    'publication_count TEXT',\n",
    "    'notes TEXT',\n",
    "    'update_time TEXT',\n",
    "]\n",
    "for col in inttable_cols:\n",
    "    inttable_create.append(f'    {col},')\n",
    "inttable_create = '\\n'.join(inttable_create).strip(',')\n",
    "inttable_create += '\\n);'\n",
    "table_create_sql.append(inttable_create)\n",
    "print(len(insert_sql))\n",
    "\n",
    "biogrid.update(uniprots)\n",
    "intact.update(uniprots)\n",
    "dbtables = [intact.get_latest(), biogrid.get_latest()]\n",
    "for d in dbtables:\n",
    "    if 'Unnamed: 0' in d.columns:\n",
    "        d.drop(columns=['Unnamed: 0'],inplace = True)\n",
    "shared = set()\n",
    "for i, d in enumerate(dbtables):\n",
    "    for d2 in dbtables[i+1:]:\n",
    "        shared |= (set(d2.index) & set(d.index))\n",
    "\n",
    "shared = sorted(list(shared))\n",
    "ind = 0\n",
    "if len(shared) > 0:\n",
    "    mtables = [d.loc[shared].sort_index() for d in dbtables]\n",
    "    dbtables = [d.drop(index=shared) for d in dbtables]\n",
    "new_data = []\n",
    "no_set = [c for c in mtables[0].columns if (('uniprot' not in c))]\n",
    "for c in mtables[0].columns:\n",
    "    if c == 'source_database':\n",
    "        jst = ';'\n",
    "    else:\n",
    "        jst = '__'\n",
    "    if c in no_set:\n",
    "        nc = mtables[0][c].astype(str)\n",
    "        for d in mtables[1:]:\n",
    "            nc = nc + jst + d[c].astype(str)\n",
    "        new_data.append(nc)\n",
    "    else:\n",
    "        new_data.append(mtables[0][c])\n",
    "newer_data = [\n",
    "    c.str.replace('nan','').str.strip('_') for c in new_data\n",
    "]\n",
    "shared_df = pd.DataFrame.from_dict({c: newer_data[i] for i, c in enumerate(mtables[0].columns)}).replace('__',np.nan)\n",
    "shared_df.index = mtables[0].index\n",
    "dbtables.append(shared_df)\n",
    "merg = pd.concat(dbtables)\n",
    "pm = []\n",
    "npubs = []\n",
    "for _,row in merg.iterrows():\n",
    "    pmids = set()\n",
    "    for p in row['publication_identifier'].split('__'):\n",
    "        for pp in p.split(';'):\n",
    "            if 'pubmed' in pp.lower():\n",
    "                pmids.add(pp)\n",
    "    pm.append(len(pmids))\n",
    "    npubs.append(';'.join(sorted(list(pmids))))\n",
    "merg['publication_count'] = pm\n",
    "merg['publication_identifier'] = npubs\n",
    "\n",
    "int_df_slim = merg[merg['uniprot_id_a'].isin(uniprots) & merg['uniprot_id_b'].isin(uniprots)]\n",
    "int_df_slim = int_df_slim.reset_index()\n",
    "for _,row in int_df_slim.iterrows():\n",
    "    data = [\n",
    "        row[c.split()[0]] for c in inttable_cols\n",
    "    ]\n",
    "    add_str = f'INSERT INTO known_interactions ({\", \".join([c.split()[0] for c in inttable_cols])}) VALUES ({\", \".join([\"?\" for _ in inttable_cols])})'\n",
    "    insert_sql.append([add_str, data])\n",
    "print('Knowns', len(insert_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "250812cb-7b40-426f-bffa-cee18cd43432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3178426\n",
      "v1.0 3180029\n"
     ]
    }
   ],
   "source": [
    "msmictable_create = ['CREATE TABLE IF NOT EXISTS msmicroscopy (']\n",
    "msmictable_cols = [\n",
    "    'Interaction TEXT PRIMARY KEY',\n",
    "    'Bait TEXT NOT NULL',\n",
    "    'Prey TEXT NOT NULL',\n",
    "    'Bait_norm REAL NOT NULL',\n",
    "    'Bait_sumnorm REAL NOT NULL',\n",
    "    'Loc TEXT NOT NULL',\n",
    "    'Unique_to_loc REAL NOT NULL',\n",
    "    'Loc_norm REAL NOT NULL',\n",
    "    'Loc_sumnorm REAL NOT NULL',\n",
    "    'MSMIC_version TEXT NOT NULL'\n",
    "]\n",
    "for col in msmictable_cols:\n",
    "    msmictable_create.append(f'    {col},')\n",
    "msmictable_create = '\\n'.join(msmictable_create).strip(',')\n",
    "msmictable_create += '\\n);'\n",
    "table_create_sql.append(msmictable_create)\n",
    "print(len(insert_sql))\n",
    "for dirname in os.listdir(os.path.join(datadir,'msmic')):\n",
    "    if not os.path.isdir(os.path.join(datadir, 'msmic',dirname)):\n",
    "        continue\n",
    "    version = dirname\n",
    "    ref_data = pd.read_csv(os.path.join(datadir, 'msmic', version, 'msmic_ref_table.txt'),sep='\\t')\n",
    "    loc_data = pd.read_csv(os.path.join(datadir, 'msmic', version, 'msmic_localizations.txt'),sep='\\t')\n",
    "    loc_col = 'Organelle'\n",
    "\n",
    "    loc_data[loc_col] = [s.capitalize().strip() for s in loc_data[loc_col].values]\n",
    "    baitnorm = []\n",
    "    baitsumnorm = []\n",
    "    preys_in_baits = {}\n",
    "    preys_in_localizations = {}\n",
    "    db_bait_max = {}\n",
    "    db_bait_sum= {}\n",
    "    for b in ref_data['Bait'].unique():\n",
    "        db_bait_max[b] = max(ref_data[ref_data['Bait']==b]['AvgSpec'].values)\n",
    "        db_bait_sum[b] = sum(ref_data[ref_data['Bait']==b]['AvgSpec'].values)\n",
    "    for _,row in ref_data.iterrows():\n",
    "        if row['Prey'] not in preys_in_baits:\n",
    "            preys_in_baits[row['Prey']] = {}\n",
    "            preys_in_localizations[row['Prey']] = {}\n",
    "        preys_in_baits[row['Prey']][row['Bait']] = row['AvgSpec']\n",
    "        baitnorm.append(row['AvgSpec']/db_bait_max[row['Bait']])\n",
    "        baitsumnorm.append(row['AvgSpec']/db_bait_sum[row['Bait']])\n",
    "        localization = loc_data[loc_data['Bait']==row['Bait']].iloc[0][loc_col]\n",
    "        if localization not in preys_in_localizations:\n",
    "            preys_in_localizations[row['Prey']][localization] = []\n",
    "        preys_in_localizations[row['Prey']][localization].append(row['AvgSpec'])\n",
    "    ref_data['Bait_norm'] = baitnorm    \n",
    "    ref_data['Bait_sumnorm'] = baitsumnorm\n",
    "    unique_preys = [p for p, v in preys_in_localizations.items() if len(v) == 1]\n",
    "    ref_data['Loc'] = [loc_data[loc_data['Bait']==bait].iloc[0][loc_col] for bait in ref_data['Bait'].values]\n",
    "    ref_data['Unique_to_loc'] = [prey in unique_preys for prey in ref_data['Prey'].values]\n",
    "\n",
    "    uref = ref_data[ref_data['Unique_to_loc']].copy()\n",
    "    locnorm = []\n",
    "    locsumnorm = []\n",
    "    loc_max = {}\n",
    "    loc_sum = {}\n",
    "    for l in uref['Loc'].unique():\n",
    "        loc_max[l] = uref[uref['Loc']==l]['AvgSpec'].max()\n",
    "        loc_sum[l] = uref[uref['Loc']==l]['AvgSpec'].sum()\n",
    "    for _,row in uref.iterrows():\n",
    "        locnorm.append(row['AvgSpec']/loc_max[row['Loc']])\n",
    "        locsumnorm.append(row['AvgSpec']/loc_sum[row['Loc']])\n",
    "    uref['Loc_norm'] = locnorm\n",
    "    uref['Loc_sumnorm'] = locsumnorm\n",
    "    uref['MSMIC_version'] = version\n",
    "    uref['Interaction'] = uref['Bait']+uref['Prey']\n",
    "\n",
    "    for _,row in uref.iterrows():\n",
    "        data = [\n",
    "            row[c.split()[0]] for c in msmictable_cols\n",
    "        ]\n",
    "        add_str = f'INSERT INTO msmicroscopy ({\", \".join([c.split()[0] for c in msmictable_cols])}) VALUES ({\", \".join([\"?\" for _ in msmictable_cols])})'\n",
    "        insert_sql.append([add_str, data])\n",
    "    print(version, len(insert_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09838961-a88c-4c3b-b65b-d2fa5ac28893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table creation and data insertion took 12 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to the database (create it if it doesn't exist)\n",
    "conn = sqlite3.connect(os.path.join(dbdir,'proteogyver2.db'))\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "start = datetime.now()\n",
    "for create_table_str in table_create_sql:\n",
    "    cursor.execute(create_table_str)\n",
    "for insert_str, insert_data in insert_sql:\n",
    "    cursor.execute(insert_str, insert_data)\n",
    "print('Table creation and data insertion took', (datetime.now() - start).seconds, 'seconds')\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d305d6c-c730-4059-bffb-71475813fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('control_sets',), ('crapome_sets',), ('proteins',), ('control_vl_gfp_mac3_ap_overall',), ('control_vl_gfp_mac3_ap',), ('control_vl_gfp_mac3_bioid_overall',), ('control_vl_gfp_mac3_bioid',), ('control_vl_gfp_mac2_ap_overall',), ('control_vl_gfp_mac2_ap',), ('control_vl_gfp_mac2_bioid_overall',), ('control_vl_gfp_mac2_bioid',), ('control_vl_gfp_mac_ap_overall',), ('control_vl_gfp_mac_ap',), ('control_vl_gfp_mac_ap_nls_overall',), ('control_vl_gfp_mac_ap_nls',), ('control_vl_gfp_mac_bioid_overall',), ('control_vl_gfp_mac_bioid',), ('control_vl_gfp_mac_bioid_nls_overall',), ('control_vl_gfp_mac_bioid_nls',), ('crapome_vl_gfp_mac3_ap',), ('crapome_vl_gfp_mac3_bioid',), ('crapome_vl_gfp_mac2_ap',), ('crapome_vl_gfp_mac2_bioid',), ('crapome_vl_gfp_mac_ap',), ('crapome_vl_gfp_mac_ap_nls',), ('crapome_vl_gfp_mac_bioid',), ('crapome_vl_gfp_mac_bioid_nls',), ('crapome_nesvilab',), ('contaminants',), ('ms_runs',), ('known_interactions',), ('msmicroscopy',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "con = sqlite3.connect(os.path.join(dbdir,'proteogyver.db'))\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7feb8-18ae-4de5-8f1b-2e92cabeab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WIP_inprogress",
   "language": "python",
   "name": "wip_inprogress"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
